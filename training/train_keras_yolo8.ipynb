{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Train KerasCV-based YOLOv8 model on a specified dataset\n",
    "\n",
    "This code is heavily based on the following tutorials:\n",
    "  - [Object Detection with KerasCV](https://keras.io/guides/keras_cv/object_detection_keras_cv/#train-a-custom-object-detection-model)\n",
    "  - [Efficient Object Detection with YOLOV8 and KerasCV](https://keras.io/examples/vision/yolov8/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from pprint import pprint\n",
    "import argparse\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_cv\n",
    "from keras_cv import visualization\n",
    "from keras_cv import bounding_box\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dataset(inputs, class_names, value_range=(0, 255), rows=2, cols=2, bounding_box_format=BOUNDING_BOX_FORMAT):\n",
    "    inputs = next(iter(inputs.take(1)))\n",
    "    images, bounding_boxes = inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
    "    visualization.plot_bounding_box_gallery(\n",
    "        images,\n",
    "        value_range=value_range,\n",
    "        rows=rows,\n",
    "        cols=cols,\n",
    "        y_true=bounding_boxes,\n",
    "        scale=5,\n",
    "        font_scale=0.7,\n",
    "        bounding_box_format=bounding_box_format,\n",
    "        class_mapping=class_names,\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    \"\"\"\n",
    "    Loads an image\n",
    "\n",
    "    Based on https://keras.io/examples/vision/yolov8/\n",
    "    \"\"\"\n",
    "\n",
    "    image = tf.io.read_file(image_path)\n",
    "    return tf.image.decode_jpeg(image, channels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO annotation file parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_YOLO_annotations(annot_path: str):\n",
    "    \"\"\"\n",
    "    Parses a YOLO annotation file\n",
    "\n",
    "    Based on https://keras.io/examples/vision/yolov8/\n",
    "    \"\"\"\n",
    "\n",
    "    boxes: list[tuple] = []\n",
    "    classes: list[int] = []\n",
    "\n",
    "    with open(annot_path, newline=\"\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file, delimiter=\" \")\n",
    "        for row in reader:\n",
    "\n",
    "            # Convert bounding box coords from center to top-left\n",
    "            box_center_x, box_center_y, box_w, box_h = tuple(float(val) for val in row[1:5])\n",
    "            box_x = box_center_x - box_w/2\n",
    "            box_y = box_center_y - box_h/2\n",
    "            boxes.append((box_x, box_y, box_w, box_h))\n",
    "\n",
    "            classes.append(int(row[0]))\n",
    "\n",
    "    return boxes, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateCOCOMetricsCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, data, save_path):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.metrics = keras_cv.metrics.BoxCOCOMetrics(\n",
    "            bounding_box_format=BOUNDING_BOX_FORMAT,\n",
    "            evaluate_freq=1e9,\n",
    "        )\n",
    "\n",
    "        self.save_path = save_path\n",
    "        self.best_map = -1.0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.metrics.reset_state()\n",
    "        for batch in self.data:\n",
    "            images, y_true = batch[0], batch[1]\n",
    "            y_pred = self.model.predict(images, verbose=0)\n",
    "            self.metrics.update_state(y_true, y_pred)\n",
    "\n",
    "        metrics = self.metrics.result(force=True)\n",
    "        logs.update(metrics)\n",
    "\n",
    "        current_map = metrics[\"MaP\"]\n",
    "        if current_map > self.best_map:\n",
    "            self.best_map = current_map\n",
    "            self.model.save(self.save_path)  # Save the model when mAP improves\n",
    "\n",
    "        return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"birdsyolo-v0.1\"\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "IMAGES_PATH = f\"images/{MODEL_NAME}/images\"\n",
    "ANNOTATIONS_PATH = f\"images/{MODEL_NAME}/annotations\"\n",
    "CLASS_NAMES_PATH = f\"models/{MODEL_NAME}/annotations\"\n",
    "DATASET_BOUNDING_BOX_FORMAT = \"rel_xywh\"\n",
    "\n",
    "SAVE_PATH = f\"models/{MODEL_NAME}/model.keras\"\n",
    "\n",
    "SPLIT_RATIO = 0.2\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 0.001\n",
    "GLOBAL_CLIPNORM = 10.0\n",
    "TARGET_SIZE = (640, 640)\n",
    "MODEL_BACKBONE = \"resnet50_imagenet\"\n",
    "BOUNDING_BOX_FORMAT = \"xywh\"\n",
    "TAKE = 20 # Set to -1 to train on full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load annotations and image paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "boxes = []\n",
    "classes = []\n",
    "for annot_file in filter(lambda p: p.endswith(\".txt\"), os.listdir(ANNOTATIONS_PATH)):\n",
    "    basename = os.path.splitext(annot_file)[0]\n",
    "    found_img = False\n",
    "    for ext in [\".jpg\", \".jpeg\"]:\n",
    "        img_path = os.path.join(IMAGES_PATH, basename + ext)\n",
    "        if os.path.exists(img_path):\n",
    "            found_img = True\n",
    "            break\n",
    "\n",
    "    if not found_img:\n",
    "        continue\n",
    "\n",
    "    annot_boxes, annot_classes = parse_YOLO_annotations(os.path.join(ANNOTATIONS_PATH, annot_file))\n",
    "\n",
    "    image_paths.append(img_path)\n",
    "    boxes.append(annot_boxes)\n",
    "    classes.append(annot_classes)\n",
    "\n",
    "n_images = len(image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load class names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CLASS_NAMES_PATH, 'r', newline=\"\") as class_names_f:\n",
    "    class_names = class_names_f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data into dataset from ragged tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = tf.ragged.constant(image_paths)\n",
    "boxes = tf.ragged.constant(boxes)\n",
    "classes = tf.ragged.constant(classes)\n",
    "data = tf.data.Dataset.from_tensor_slices((image_paths, classes, boxes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into validation and training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_val = int(n_images * SPLIT_RATIO)\n",
    "\n",
    "val_data = data.take(num_val)\n",
    "train_data = data.skip(num_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map datasets to loading and transforming function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(image_path, classes, boxes):\n",
    "    image = load_image(image_path)\n",
    "    boxes = keras_cv.bounding_box.convert_format(\n",
    "        boxes.to_tensor(),\n",
    "        images=image,\n",
    "        source=DATASET_BOUNDING_BOX_FORMAT,\n",
    "        target=BOUNDING_BOX_FORMAT\n",
    "    )\n",
    "    bounding_boxes = {\n",
    "        \"classes\": tf.cast(classes, dtype=tf.float32),\n",
    "        \"boxes\": boxes,\n",
    "    }\n",
    "    return {\"images\": tf.cast(image, tf.float32), \"bounding_boxes\": bounding_boxes}\n",
    "\n",
    "train_ds = train_data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle train data and convert to ragged_batch and visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.shuffle(BATCH_SIZE * 4)\n",
    "train_ds = train_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
    "visualize_dataset(\n",
    "    train_ds,\n",
    "    value_range=(0, 255),\n",
    "    rows=2,\n",
    "    cols=2,\n",
    "    class_names=class_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert validation data to ragged_batch and visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = val_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
    "visualize_dataset(val_ds, class_names=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply image augmentation to train data and visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = keras.Sequential(\n",
    "    layers=[\n",
    "        keras_cv.layers.RandomFlip(mode=\"horizontal\", bounding_box_format=BOUNDING_BOX_FORMAT),\n",
    "        keras_cv.layers.RandomFlip(mode=\"vertical\", bounding_box_format=BOUNDING_BOX_FORMAT),\n",
    "        #keras_cv.layers.RandomShear( # corrupts bounding box locations\n",
    "        #    x_factor=0.2, y_factor=0.2, bounding_box_format=BOUNDING_BOX_FORMAT\n",
    "        #),\n",
    "        keras_cv.layers.JitteredResize(\n",
    "            target_size=TARGET_SIZE, scale_factor=(0.75, 1.3), bounding_box_format=BOUNDING_BOX_FORMAT\n",
    "        ),\n",
    "    ],\n",
    "    name=\"augmentation\"\n",
    ")\n",
    "\n",
    "train_ds = train_ds.map(augmentation, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "visualize_dataset(train_ds, class_names=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply resize to validation data and visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = keras_cv.layers.Resizing(\n",
    "    *TARGET_SIZE, bounding_box_format=BOUNDING_BOX_FORMAT, pad_to_aspect_ratio=True\n",
    ")\n",
    "\n",
    "val_ds = val_ds.map(resize, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "visualize_dataset(train_ds, class_names=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map train and validation dataset to the correct format for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_tuple(inputs):\n",
    "    return inputs[\"images\"], bounding_box.to_dense(\n",
    "        inputs[\"bounding_boxes\"], max_boxes=32\n",
    "    )\n",
    "\n",
    "train_ds = train_ds.map(input_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(input_tuple, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prefetch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a subset of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.take(TAKE)\n",
    "val_ds = val_ds.take(TAKE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_cv.models.YOLOV8Detector.from_preset(\n",
    "    MODEL_BACKBONE,\n",
    "    bounding_box_format=BOUNDING_BOX_FORMAT,\n",
    "    num_classes=NUM_CLASSES,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.legacy.SGD(\n",
    "    learning_rate=LEARNING_RATE, momentum=0.9, global_clipnorm=GLOBAL_CLIPNORM\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    classification_loss=\"binary_crossentropy\",\n",
    "    box_loss=\"ciou\",\n",
    "    optimizer=optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[EvaluateCOCOMetricsCallback(val_ds, \"model.h5\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
